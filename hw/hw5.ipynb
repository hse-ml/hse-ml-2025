{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ef7ac2-710b-4b82-a8b6-554e636a3142",
   "metadata": {},
   "source": [
    "# Домашнее задание: реализовать GPT-модель с Mixture of Experts слоями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07078c7-3a0e-4e34-9441-ebfbcced5765",
   "metadata": {},
   "source": [
    "## Домашнее задание\n",
    "\n",
    "- Расширьте данный пример, добавив реализацию RMSNorm и rotary embeddings. **(4 балла)**\n",
    "- Проведите эксперимент по изменению числа экспертов и размера модели. **(4 балла)**\n",
    "- Опишите, как scaling laws влияют на производительность модели. **(2 балла)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b480c432-91ce-4205-9cac-679f1d766c25",
   "metadata": {},
   "source": [
    "## Обзор Mixture of Experts (MoE)\n",
    "\n",
    "Mixture of Experts (MoE) – это подход, позволяющий масштабировать модели путём распределения вычислительных задач между несколькими \"экспертами\". Для каждого входа вычисляется распределение вероятностей по экспертам с помощью \"гейтинговой\" сети, и итоговый выход получается как взвешенная сумма выходов экспертов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9499041b-d024-4cd8-814b-0cd33d786521",
   "metadata": {},
   "source": [
    "### Задачи метода MoE:\n",
    "1. Увеличение параметров модели без линейного роста вычислительной нагрузки.\n",
    "2. Обучение специализированных подсетей для различных аспектов данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ecc159-66cb-42a6-891b-e23b0fd0361d",
   "metadata": {},
   "source": [
    "В следующих ячейках представлен упрощённый пример реализации MoE-слоя и его интеграции в трансформер-блок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a859fc84-880f-4dab-ae03-c38dc469e497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58740db2-de6a-4506-b905-4c4510e54dfc",
   "metadata": {},
   "source": [
    "## Реализация MoE-слоя\n",
    "\n",
    "В этой части мы создадим упрощённый класс MoE, где каждый эксперт – это простая линейная трансформация, а гейтинговая сеть определяет веса для каждого эксперта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7fb692c-0dff-4881-9a92-ffe3bbbcfdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример шаблонной реализации MoE (требует доработки)\n",
    "\n",
    "\n",
    "class MixtureOfExperts(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_experts=4):\n",
    "        super(MixtureOfExperts, self).__init__()\n",
    "        self.num_experts = num_experts\n",
    "\n",
    "        # создаь список экспертов (каждый эксперт - линейное преобразование)\n",
    "        self.experts = nn.ModuleList(\n",
    "            [nn.Linear(input_dim, output_dim) for _ in range(num_experts)]\n",
    "        )\n",
    "\n",
    "        # Гейтинговая сеть для определения весов\n",
    "        self.gate = nn.Linear(input_dim, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # вычислите gate_scores, gate_probs\n",
    "        # примените экспертов к входу x и объедините результаты с использованием весов\n",
    "        # подсказка: используйте torch.stack и torch.sum\n",
    "        # например, gate_scores = self.gate(x)\n",
    "\n",
    "        gate_scores = self.gate(x)\n",
    "        gate_probs = F.softmax(gate_scores, dim=-1)\n",
    "\n",
    "        # Применяем каждого эксперта\n",
    "        expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=-1)\n",
    "        # Расширьте размеры gate_probs для совместимости\n",
    "        gate_probs = gate_probs.unsqueeze(2)\n",
    "\n",
    "        # Взвешенная сумма выходов экспертов\n",
    "        output = torch.sum(expert_outputs * gate_probs, dim=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b795d6a-89d4-4ff5-ae8f-ee7d0cf41c3e",
   "metadata": {},
   "source": [
    "#### Проверьте работу MoE-слоя на тестовом входе (при необходимости)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db10ae7-aac6-4d4e-9358-ca187efcb712",
   "metadata": {},
   "source": [
    "## Объяснение реализации MoE-слоя\n",
    "\n",
    "- **self.experts:** Список линейных слоёв, каждый из которых является \"экспертом\".\n",
    "- **self.gate:** Линейный слой, выдающий веса для каждого эксперта.\n",
    "- **forward:** Вычисляется softmax по выходу гейта, затем каждое линейное преобразование применяется к входу и комбинируется с помощью весов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ded4d448-a99f-4c91-bbd6-fd717977e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# класс TransformerBlockMoE (требует доработки)\n",
    "\n",
    "\n",
    "class TransformerBlockMoE(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_experts=4):\n",
    "        super(TransformerBlockMoE, self).__init__()\n",
    "        # многоголовое внимание\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim=d_model, num_heads=num_heads, batch_first=True\n",
    "        )\n",
    "        # слои нормализации\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        # MoE слой вместо стандартного feed-forward слоя\n",
    "        self.moe = MixtureOfExperts(d_model, d_ff, num_experts=num_experts)\n",
    "        # приводим к исходной размерности\n",
    "        self.fc = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # шаг 1: Многоголовое внимание\n",
    "        attn_output, _ = self.attn(x, x, x)\n",
    "        x = self.norm1(x + attn_output)\n",
    "\n",
    "        # шаг 2: Применение MoE слоя с активацией ReLU\n",
    "        moe_output = self.moe(x)\n",
    "        ff_output = self.fc(F.relu(moe_output))\n",
    "        x = self.norm2(x + ff_output)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f321d048-c555-4237-9920-92371997b4bb",
   "metadata": {},
   "source": [
    "## Объяснение трансформер-блока с MoE\n",
    "\n",
    "- **Многоголовое внимание:** Стандартное self-attention.\n",
    "- **norm1 и norm2:** Слои нормализации для стабилизации обучения.\n",
    "- **MoE-слой:** Заменяет обычный feed-forward слой.\n",
    "- **fc:** Линейное преобразование для приведения размерности обратно к d_model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cfb810-c311-430d-bf3b-1bb2a896519c",
   "metadata": {},
   "source": [
    "## Тестирование трансформер-блока с MoE\n",
    "\n",
    "В следующей ячейке создадим тестовый пример:\n",
    "- Сгенерируем случайный вход (например, эмбеддинги токенов)\n",
    "- Пропустим вход через блок и выведем форму выходного тензора.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "846f2723-3598-49aa-aed5-55aa946237bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма входного тензора: torch.Size([2, 10, 32])\n",
      "Форма выходного тензора: torch.Size([2, 10, 32])\n"
     ]
    }
   ],
   "source": [
    "# Тестовый пример использования TransformerBlockMoE\n",
    "\n",
    "# Задайте параметры модели\n",
    "batch_size = 2\n",
    "seq_len = 10\n",
    "d_model = 32\n",
    "num_heads = 4\n",
    "d_ff = 64\n",
    "\n",
    "# Сгенерируйте случайный вход\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "# Инициализируйте блок трансформера с MoE\n",
    "transformer_block = TransformerBlockMoE(d_model, num_heads, d_ff, num_experts=4)\n",
    "\n",
    "# Пропустите вход через блок\n",
    "output = transformer_block(x)\n",
    "\n",
    "# Выведите формы входного и выходного тензоров\n",
    "print(\"Форма входного тензора:\", x.shape)\n",
    "print(\"Форма выходного тензора:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdaee4e-10ed-4ca3-894d-b61038b7ef5d",
   "metadata": {},
   "source": [
    "## Дополнительные темы для изучения\n",
    "\n",
    "- **RMSNorm:** Альтернатива стандартной нормализации для улучшения обучения.\n",
    "- **Rotary embeddings:** Улучшают представление позиционной информации.\n",
    "- **Grouped Query Attention:** Модификация механизма внимания для повышения эффективности.\n",
    "\n",
    "*Попробуйте самостоятельно интегрировать эти элементы в модель.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e3ae68-a77b-4f50-afea-92d28e1ae830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
